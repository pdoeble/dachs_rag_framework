ğŸŸ§ TICKET 1 â€” MÃ¼ll-Chunks vor LLM filtern
Titel

Filter meaningless Chunks before semantic annotation

Beschreibung

Die Statistik zeigt, dass ~20â€“30 % aller Chunks keinen fachlichen Inhalt enthalten (z. B. ".", Kapitelnummern, Seitenfragmente, Tabellenfragmente).
Diese Chunks fÃ¼hren regelmÃ¤ÃŸig zu leeren Feldern in domain, content_type, artifact_role und sinnlosen summary_short-Werten.

Diese Chunks dÃ¼rfen nicht ans LLM geschickt werden.

Akzeptanzkriterien

Chunks mit weniger als 5 Zeichen werden ohne LLM annotiert.

Chunks, die nur aus Ziffern, Punkt, Komma, Leerzeichen oder Bindestrichen bestehen, werden ohne LLM annotiert.

Annotation fÃ¼r diese Chunks enthÃ¤lt:

artifact_role=["structural"]

trust_level="low"

leere Listen fÃ¼r alle anderen Felder

Technische Aufgaben

Datei Ã¶ffnen:
scripts/annotate_semantics.py

In process_file(), vor classify_chunk(), Filterregeln einbauen.

Implementation exakt wie im Analysevorschlag.

ğŸŸ§ TICKET 2 â€” Heading-Chunks mit erweitertem Kontext annotieren
Titel

Improve semantic annotation of heading-only chunks using neighbor context

Beschreibung

Heading-Chunks (z. B. "12.4.2 Hierarchical Clustering") enthalten nicht genug Text, um Domain, Content-Type oder artifact_role korrekt zu bestimmen.
Ohne Kontext bleiben Domain & artifact_role hÃ¤ufig leer.

Diese Chunks sollen automatisch mit erweitertem Kontext (nÃ¤chster und ggf. Ã¼bernÃ¤chster Chunk) an das LLM Ã¼bergeben werden.

Akzeptanzkriterien

Wenn meta.has_heading == True und content < 40 Zeichen:
â†’ mindestens der nÃ¤chste Chunk wird als Kontext Ã¼bergeben.

Optional: zusÃ¤tzlich der zweite Folgechunk, falls vorhanden.

Domain- und artifact_role-Quote verbessert sich messbar.

Technische Aufgaben

Datei Ã¶ffnen:
scripts/annotate_semantics.py

In process_file() Heading-Erkennung implementieren:
is_heading = rec["meta"].get("has_heading", False)

Kontextvariablen next_text und next2_text erweitern.

Kontext an die Funktion classify_chunk() Ã¼bergeben.

ğŸŸ§ TICKET 3 â€” artifact_role Defaults fÃ¼r strukturelle Chunks
Titel

Assign default artifact_role for structural chunks (heading/table/figure)

Beschreibung

artifact_role ist in 65 % der Chunks leer.
Viele dieser Chunks sind aber klar strukturelle Elemente wie:

Ãœberschriften

TabellenanfÃ¤nge

Abbildungsbeschriftungen

Diese sollen standardmÃ¤ÃŸig Rollen erhalten, ohne dass das LLM bemÃ¼ht wird.

Akzeptanzkriterien

Chunk mit meta.has_heading == true erhÃ¤lt artifact_role=["heading"]

Chunk mit meta.has_table == true erhÃ¤lt artifact_role=["table"]

Das passiert zusÃ¤tzlich zur normalen LLM-Annotation.

artifact_role-FÃ¼llquote steigt auf >50 %

Technische Aufgaben

Datei Ã¶ffnen: scripts/annotate_semantics.py

In normalize_semantic_result() Default-Append implementieren.

Keine bestehenden Rollen Ã¼berschreiben.

ğŸŸ§ TICKET 4 â€” summary_short fÃ¼r strukturelle Chunks unterdrÃ¼cken
Titel

Suppress summary_short generation for non-informative structural chunks

Beschreibung

23 % der summary_short Werte sind <10 Zeichen.
Ursache: Ãœberschriften, Tabellenfragmente, oder so kurze Chunks, dass keine echte Zusammenfassung existiert.

Diese Summaries sollen nicht erzeugt werden.

Akzeptanzkriterien

Bei Headings, Tabellen, extrem kurzen Texten (<40 Zeichen):
â†’ summary_short wird auf "" gesetzt.

Keine Mini-Summaries wie ".", "â€“", "Table", "Heading", etc.

Technische Aufgaben

Datei Ã¶ffnen: scripts/annotate_semantics.py

In normalize_semantic_result() entsprechende Abfrage implementieren.

LLM-Antworten ggf. Ã¼berschreiben, wenn strukturelle Chunks.

ğŸŸ§ TICKET 5 â€” Prompt hÃ¤rten fÃ¼r nicht annotierbare Chunks
Titel

Extend system prompt to force empty JSON for meaningless chunks

Beschreibung

Das LLM versucht manchmal, auch bei inhaltslosen Chunks sinnlose Klassifikationen zu erzeugen.
Der Prompt muss klar definieren, wie bei â€non-meaningful contentâ€œ zu antworten ist.

Akzeptanzkriterien

system_prompt enthÃ¤lt eine Regel wie:

If theft (less than 5 characters,
only punctuation, or only numbers), return empty lists and an empty summary.


LLM soll zuverlÃ¤ssig â€leereâ€œ JSON-Objekte erzeugen.

Technische Aufgaben

Datei Ã¶ffnen: scripts/annotate_semantics.py

system_prompt erweitern (in LLMSemanticClassifier.classify_chunk()).

Keine Logik im Prompt Ã¤ndern, nur ErgÃ¤nzung.

ğŸŸ§ TICKET 6 â€” Hook fÃ¼r zukÃ¼nftigen FAISS-Kontext einbauen
Titel

Add placeholder hook for FAISS similarity context inside LLM prompt builder

Beschreibung

SpÃ¤ter soll das LLM Ã¤hnliche Chunks per FAISS finden und als Kontext nutzen kÃ¶nnen.
DafÃ¼r ist ein klarer Einbaupunkt nÃ¶tig.

Akzeptanzkriterien

Im Prompt-Aufbau existiert ein kommentierter Codeblock:

# TODO: Insert FAISS neighbor retrieval here


Dieser Block steht VOR dem finalen prompt assembly.

Kein funktionaler Code nÃ¶tig â€“ nur Platzhalter.

Technische Aufgaben

Datei Ã¶ffnen: scripts/annotate_semantics.py

Suche den Bereich, wo user_prompt gebaut wird.

TODO-Kommentar einfÃ¼gen.

ğŸŸ§ TICKET 7 â€” Verbesserung der Sprache (Language fallback)
Titel

Improve language assignment for low-information chunks

Beschreibung

Chunks ohne alphabetische Zeichen (nur Zahlen/Punkt/Tabellen) werden fÃ¤lschlich als â€enâ€œ erkannt.
Diese Chunks sollen language="unknown" erhalten.

Akzeptanzkriterien

Bei allen nicht annotierbaren Chunks â†’ Sprache = "unknown"

Sprache nicht vom LLM korrigieren lassen.

Technische Aufgaben

In process_file() direkt vor dem Output:
Wenn MÃ¼ll-Chunk â†’ Sprache Ã¼berschreiben mit "unknown".